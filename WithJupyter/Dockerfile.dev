FROM phusion/baseimage:jammy-1.0.1

WORKDIR '/mnt/'

ENV SPARK_VERSION = 3.3.1 \
HADOOP_VERSION = 3

RUN mkdir /mnt/hadoop
RUN mkdir /mnt/spark
RUN mkdir /mnt/livy
RUN mkdir /mnt/jupyter

ENV SPARK_HOME = /mnt/spark 
ENV HADOOP_HOME = /mnt/hadoop

ENV SPARK_MASTER_PORT=7077 \
    SPARK_MASTER_WEBUI_PORT=8080 \
    SPARK_LOG_DIR=/mnt/spark/logs \
    SPARK_MASTER_LOG=/mnt/spark/logs/spark-master.out \
    SPARK_WORKER_LOG=/mnt/spark/logs/spark-worker.out \
    SPARK_WORKER_WEBUI_PORT=8080 \
    SPARK_WORKER_PORT=7000 \
    SPARK_MASTER="spark://spark-master:7077" \
    SPARK_WORKLOAD="master"

RUN ["apt","update","-y"]
#RUN ["apt","upgrade","-y"]
RUN apt install -y wget default-jdk scala python3 python3-pip 
# iproute2 openssh-client openssh-server git unzip
RUN wget --no-verbose -O spark.tgz https://dlcdn.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz
RUN tar xvf spark.tgz \
    && rm -rf spark.tgz
RUN cp -rf /mnt/spark-3.3.2-bin-hadoop3/* /mnt/spark/ \
    && rm -rf /mnt/spark-3.3.2-bin-hadoop3
RUN echo "export SPARK_HOME=/mnt/spark" >> ~/.profile
ENV PATH=$PATH:/mnt/spark/bin:/mnt/spark/sbin:/mnt/livy/bin
RUN echo "export PATH=$PATH" >> ~/.profile
RUN echo "export PYSPARK_PYTHON=/usr/bin/python3" >> ~/.profile \
    && . ~/.profile


RUN pip3 install notebook && pip3 install findspark
RUN unset SPARK_HOME

COPY ./Service-Start.sh ./Service-Start.sh 
COPY ./TestSpark.ipynb /mnt/jupyter/TestSpark.ipynb
CMD bash ./Service-Start.sh