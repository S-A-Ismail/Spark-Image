FROM phusion/baseimage:jammy-1.0.1

WORKDIR '/mnt/'

ENV SPARK_VERSION = 3.3.1 \
HADOOP_VERSION = 3

RUN mkdir /mnt/hadoop
RUN mkdir /mnt/spark
RUN mkdir /mnt/livy
RUN mkdir /mnt/jupyter

ENV SPARK_HOME = /mnt/spark 
ENV HADOOP_HOME = /mnt/hadoop

ENV SPARK_MASTER_PORT=7077 \
    SPARK_MASTER_WEBUI_PORT=8080 \
    SPARK_LOG_DIR=/mnt/spark/logs \
    SPARK_MASTER_LOG=/mnt/spark/logs/spark-master.out \
    SPARK_WORKER_LOG=/mnt/spark/logs/spark-worker.out \
    SPARK_WORKER_WEBUI_PORT=8080 \
    SPARK_WORKER_PORT=7000
    #SPARK_MASTER="spark://spark-master:7077" \
    #SPARK_WORKLOAD="master"

RUN ["apt","update","-y"]
RUN ["apt","upgrade","-y"]
RUN apt install -y wget default-jdk scala python3 python3-pip 
RUN wget --no-verbose -O spark.tgz https://dlcdn.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz
RUN tar xvf spark.tgz \
    && rm -rf spark.tgz
RUN cp -rf /mnt/spark-3.3.2-bin-hadoop3/* /mnt/spark/ \
    && rm -rf /mnt/spark-3.3.2-bin-hadoop3
RUN echo "export SPARK_HOME=/mnt/spark" >> ~/.profile
ENV PATH=$PATH:/mnt/spark/bin:/mnt/spark/sbin:/mnt/livy/bin
RUN echo "export PYTHONPATH=/mnt/spark/python:/usr/bin/python3" >> ~/.profile
RUN echo "export PATH=$PATH" >> ~/.profile
RUN echo "export PYSPARK_PYTHON=/usr/bin/python3" >> ~/.profile
RUN echo 'export PYSPARK_DRIVER_PYTHON="jupyter"' >> ~/.profile
RUN echo 'export PYSPARK_DRIVER_PYTHON_OPTS="notebook"' >> ~/.profile
RUN . ~/.profile

RUN pip3 install notebook && pip3 install findspark && pip3 install spylon-kernel && pip install toree && pip install py4j
RUN jupyter toree install --user --spark_home=/mnt/spark/
RUN python3 -m spylon_kernel install

RUN mkdir /mnt/spark/logs
COPY ./Service-Start.sh ./Service-Start.sh 
COPY ./TestSpark.ipynb /mnt/jupyter/TestSpark.ipynb
CMD bash ./Service-Start.sh